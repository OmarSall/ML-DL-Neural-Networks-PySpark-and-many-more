{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de6ca8f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed311094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "dict = {\n",
    "    'one':1,\n",
    "    'two':2,\n",
    "    'three':3\n",
    "}\n",
    "\n",
    "### add code ###\n",
    "total_sum = sum(dict.values())\n",
    "print(total_sum)\n",
    "#result should be 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca022fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nresult should be:\\n0\\n1\\n2\\n3\\n4\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0 \n",
    "### add code ###\n",
    "for i in range(0,5):\n",
    "    print(i)\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "\"\"\"\n",
    "result should be:\n",
    "0\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "\"\"\"    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b12358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "numbers = [9,2,5,11,4,3]\n",
    "\n",
    "### add code ###\n",
    "largest = max(numbers)\n",
    "\n",
    "print(largest)\n",
    "\n",
    "#result should be 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72328577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "func1 = lambda x: x*2\n",
    "func2 = lambda x: x*3\n",
    "result = 2\n",
    "result = func1(result)\n",
    "results = func2(result)\n",
    "\n",
    "### add code ###\n",
    "\n",
    "result = func1(result)\n",
    "result = 8\n",
    "\n",
    "print(result) # should be 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4543e826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.75, 3.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([2,9,4,6,2,3,1,3])\n",
    "mean = np.mean(x)\n",
    "\n",
    "### add code ###\n",
    "median = np.median(x)\n",
    "(mean,median)  #should be (3.75, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367696dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_scores = pd.DataFrame({'name':['Adam','Fred','Gloria','Laura'],\n",
    "                         'score':[80,89,71,79],\n",
    "                         'subject':['CS1', 'DS2','DS2','CS1']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17e253b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DS2</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DS2</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CS1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject  score\n",
       "0     CS1     80\n",
       "1     DS2     89\n",
       "2     DS2     71\n",
       "3     CS1     79"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores[['subject','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ed43c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         score\n",
      "subject       \n",
      "CS1       79.5\n",
      "DS2       80.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    subject  score\\n0   CS1       79.5\\n1   DS2       80.0\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### add code ###\n",
    "df_scores_grouped = df_scores.groupby(['subject']).mean()\n",
    "print(df_scores_grouped)\n",
    "\n",
    "\"\"\"\n",
    "    subject  score\n",
    "0   CS1       79.5\n",
    "1   DS2       80.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63761d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.7, 2.9, 4.2, 1.3],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [7.7, 2.8, 6.7, 2. ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train[:5]\n",
    "\n",
    "#result should be array([[4.6,3.6,1.,0.2],[5.7,4.4,1.5,0.4],[6.7,3.1,4.4,1.4],[4.8,3.4,1.6,0.2],[4.4,3.2,1.3,0.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387ee21",
   "metadata": {},
   "source": [
    "test_size:float or int, default=None\n",
    "\n",
    "If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. \n",
    "\n",
    "If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If train_size is also None, it will be set to 0.25.\n",
    "\n",
    "random_stateint, RandomState instance or None, default=None\n",
    "\n",
    "Controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ada7e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext \n",
    "\n",
    "###add code ###\n",
    "\n",
    "# You can create SparkContext by programmatically using its constructor, and pass parameters like master and appName at least \n",
    "# as these are mandatory params. \n",
    "# The below example creates context with a master as local and app name as Spark_Example_App.\n",
    "\n",
    "sc = SparkContext(\"local\", \"My App\")\n",
    "\n",
    "print(sc.version)\n",
    "\n",
    "#3.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03203cb0",
   "metadata": {},
   "source": [
    "# Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f28282d",
   "metadata": {},
   "source": [
    "## 1. Numpy\n",
    "\n",
    "NumPy is a popular Python library for multi-dimensional array and matrix processing because it can be used to perform a great variety of mathematical operations. Its capability to handle linear algebra, Fourier transform, and more, makes NumPy ideal for machine learning and artificial intelligence (AI) projects, allowing users to manipulate the matrix to easily improve machine learning performance. NumPy is faster and easier to use than most other Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e864dd86",
   "metadata": {},
   "source": [
    "## 2. Scikit-learn\n",
    "Scikit-learn is a very popular machine learning library that is built on NumPy and SciPy. It supports most of the classic supervised and unsupervised learning algorithms, and it can also be used for data mining, modeling, and analysis. Scikit-learn’s simple design offers a user-friendly library for those new to machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae76830",
   "metadata": {},
   "source": [
    "## 3. Pandas\n",
    "Pandas is another Python library that is built on top of NumPy, responsible for preparing high-level data sets for machine learning and training. It relies on two types of data structures, one-dimensional (series) and two-dimensional (DataFrame). This allows Pandas to be applicable in a variety of industries including finance, engineering, and statistics. Unlike the slow-moving animals themselves, the Pandas library is quick, compliant, and flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344269f7",
   "metadata": {},
   "source": [
    "## 4. TensorFlow\n",
    "\n",
    "TensorFlow’s open-source Python library specializes in what’s called differentiable programming, meaning it can automatically compute a function’s derivatives within high-level language. Both machine learning and deep learning models are easily developed and evaluated with TensorFlow’s flexible architecture and framework. TensorFlow can be used to visualize machine learning models on both desktop and mobile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76935521",
   "metadata": {},
   "source": [
    "## 5. Seaborn\n",
    "\n",
    "Seaborn is another open-source Python library, one that is based on Matplotlib (which focuses on plotting and data visualization) but features Pandas’ data structures. Seaborn is often used in ML projects because it can generate plots of learning data. Of all the Python libraries, it produces the most aesthetically pleasing graphs and plots, making it an effective choice if you also use it for marketing and data analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be101b",
   "metadata": {},
   "source": [
    "## 6. Theano\n",
    "\n",
    "Theano is a Python library that focuses on numerical computation and is specifically made for machine learning. It is able to optimize and evaluate mathematical models and matrix calculations that use multi-dimensional arrays to create ML models. Theano is almost exclusively used by machine learning and deep learning developers or programmers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a72d80",
   "metadata": {},
   "source": [
    "## 7. Keras\n",
    "\n",
    "Keras is a Python library that is designed specifically for developing neural networks for ML models. It can run on top of Theano and TensorFlow to train neural networks. Keras is flexible, portable, user-friendly, and easily integrated with multiple functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08071e6",
   "metadata": {},
   "source": [
    "## 8. PyTorch\n",
    "\n",
    "PyTorch is an open-source machine learning Python library based on the C programming language framework, Torch. It is mainly used in ML applications that involve natural language processing or computer vision. PyTorch is known for being exceptionally fast at executing large, dense data sets and graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7128e5",
   "metadata": {},
   "source": [
    "## 9. Matplotlib\n",
    "\n",
    "Matplotlib is a Python library focused on data visualization and primarily used for creating beautiful graphs, plots, histograms, and bar charts. It is compatible with plotting data from SciPy, NumPy, and Pandas. If you have experience using other types of graphing tools, Matplotlib might be the most intuitive choice for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a5e325",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "460ba40c",
   "metadata": {},
   "source": [
    "\n",
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b415411",
   "metadata": {},
   "source": [
    "https://www.questionpro.com/blog/ml-models/\n",
    "## 1. Supervised Learning\n",
    "\n",
    "Data scientists provide input, output and feedback to build model (as the definition). \n",
    "For example, supervised machine learning is widely deployed in image recognition, utilizing a technique called classification. Supervised machine learning is also used in predicting demographics such as population growth or health metrics, utilizing a technique called regression.\n",
    "\n",
    "### Example algorithms\n",
    "\n",
    "### Linear regression\n",
    "Linear regression is used to identify relationships between the variable of interest and the inputs, and predict its values based on the values of the input variables.\n",
    "\n",
    "-> sales forecasting\n",
    "-> risk assesment\n",
    "\n",
    "### Logistic Regression\n",
    "Logistic Regression is used to determine if an input belongs to a certain group or not\n",
    "\n",
    "### Support Vector Machines\n",
    "create coordinates for each object in an n-dimensional space and uses a hyperplane to group objects by common features\n",
    "\n",
    "-> image classification\n",
    "->financial performance comparison\n",
    "\n",
    "### Decision Trees\n",
    "\n",
    "Decision trees are also classifiers that are used to determine what category an input falls into by traversing the leaf's and nodes of a tree\n",
    "\n",
    "-> predictive analytics\n",
    "-> pricing\n",
    "\n",
    "### KNN\n",
    "The k Nearest Neighbors technique involves grouping the closest objects in a dataset and finding the most frequent or average characteristics among the objects.\n",
    "\n",
    "### Random forest\n",
    "Random forest is a collection of many decision trees from random subsets of the data, resulting in a combination of trees that may be more accurate in prediction than a single decision tree.\n",
    "\n",
    "### Boosting algorithms\n",
    "Boosting algorithms, such as Gradient Boosting Machine, XGBoost, and LightGBM, use ensemble learning. They combine the predictions from multiple algorithms (such as decision trees) while taking into account the error from the previous algorithm.\n",
    "\n",
    "## 2. Unsupervised learning\n",
    "\n",
    "Use deep learning to arrive at conclusions and patterns through unlabeled training data \n",
    "-> CLUSTERING (finding structure in data)\n",
    "\n",
    "### Example algorithms\n",
    "\n",
    "### A priori\n",
    "-> sales functions\n",
    "-> word associations\n",
    "-> searcher\n",
    "\n",
    "### K-Means clustering \n",
    "The K-Means algorithm finds similarities between objects and groups them into K different clusters.\n",
    "\n",
    "-> performance monitoring\n",
    "-> searcher intent\n",
    "\n",
    "### Hierarchical Clustering\n",
    "Hierarchical clustering builds a tree of nested clusters without having to specify the number of clusters.\n",
    "\n",
    "### Artificial Neural Networks\n",
    "-> generate new, synthetic data\n",
    "-> data mining and pattern recognition\n",
    "\n",
    "## 3. Semi-supervised learning\n",
    "Builds a model through a mix of labeled and unlabeled data, a set of categories, suggestions and exampled labels.\n",
    "\n",
    "### Example algorithms\n",
    "\n",
    "### Generative adversarial networks\n",
    "-> audio and video manipulation\n",
    "-> data creation\n",
    "\n",
    "### Self-trained Naive Bayes classifier\n",
    "\n",
    "## 4. Reinforcement learning\n",
    "Self-interpreting but based ona system of rewards and punishments learned through trial and error, seeking maximum reward\n",
    "\n",
    "### Example algoritms\n",
    "\n",
    "### Q-learning\n",
    "-> policy creation\n",
    "-> consumption reduction\n",
    "\n",
    "### Model-based value estimation\n",
    "-> linear tasks\n",
    "-> estimating parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4710db90",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827b1e7d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "203f0a1c",
   "metadata": {},
   "source": [
    "# Deep Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c389124f",
   "metadata": {},
   "source": [
    "## 1. Autoencoders\n",
    "An autoencoder is a trained neural network that replicates the data from the input layer to the output layer (for example from blurry image to clearer one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b097ed54",
   "metadata": {},
   "source": [
    "## 2. Restricted Boltzmann Machine\n",
    "\n",
    "RBM is a neural network tha can learn from a probability distribution over a set of inputs. It has 2 layers.\n",
    "\n",
    "-> classification, regresion, feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3cba63",
   "metadata": {},
   "source": [
    "## 3. Deep Belief Networks\n",
    "\n",
    "DBN are stack of Boltzmann Machines with connections between the layers and each RBM layer communicates with both the previous and subsequent layers\n",
    "-> image recognition\n",
    "-> motion capture data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab79c5c4",
   "metadata": {},
   "source": [
    "## 4. Self Organizing Map\n",
    "\n",
    "SOMs are a data visualization technique to reduce the dimensions of data through self-organizing neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a5e0bd",
   "metadata": {},
   "source": [
    "## 5. Multilayer Perceptron\n",
    " MLP is a general feedforward neural network that consists of multiple layers of perceptron with activation functions\n",
    " \n",
    " -> Image classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f34f704",
   "metadata": {},
   "source": [
    "## 6. Radial Basis Function Network\n",
    "RBFN is a special type of feedforward neural networks with radial basis functions used as activation functions\n",
    "-> classification, regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e762f50",
   "metadata": {},
   "source": [
    "## 7. Generative Adversarial Network\n",
    "GAN are generative models that create new data instances that resemble the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ac5b3",
   "metadata": {},
   "source": [
    "## 8. Recurrent Neural Network\n",
    "\n",
    "RNN have connections that form directed cycles and allows the outputs from the previous step to be fed as inputs to the current step.\n",
    "-> image capturing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fe6983",
   "metadata": {},
   "source": [
    "## 9. Convolutional Neural Network\n",
    "CNN consists of multiple different layers and are mainly used for image processing and identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c744d19",
   "metadata": {},
   "source": [
    "## 10. Long Short Term Memory Network\n",
    "LSTM are type of recurrent neural networks capable of learning and memorizing long term dependencies\n",
    "-> speech recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19669ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c60daad",
   "metadata": {},
   "source": [
    "# Cloud computing platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849066e",
   "metadata": {},
   "source": [
    "## 1. Google Cloud Platform (GCP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9749618",
   "metadata": {},
   "source": [
    "## 2. AWS - amazon web services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2da93",
   "metadata": {},
   "source": [
    "## 3. IBM Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d01e5",
   "metadata": {},
   "source": [
    "## 4. Microsoft Azure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb9f0f",
   "metadata": {},
   "source": [
    "## 5. Oracle Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9705adb",
   "metadata": {},
   "source": [
    "## 6. DigitalOcean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c7e36",
   "metadata": {},
   "source": [
    "## 7. Alibaba Cloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ec44ba",
   "metadata": {},
   "source": [
    "## 8. Apache Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2626b14b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87e99279",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
